{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 1: Import necessary libraries\n",
    "\"\"\"\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\"\n",
    "Step 2: Prepare a function to clean the raw content, removing html tags and entities\n",
    "\"\"\"\n",
    "def clean_html(raw_html, remove_tags=True):\n",
    "    \"\"\" This function cleans the raw html content by removing html tags and entities\n",
    "    - remove_tags: this is an optional parameter,\n",
    "                if True, remove html tags, otherwise keep them\n",
    "                by default, it is set to True.\n",
    "    \"\"\"\n",
    "    if remove_tags:\n",
    "        # remove HTML tags\n",
    "        cleaned_html = re.sub(r'<.*?>', ' ', raw_html)\n",
    "        # remove HTML entities\n",
    "        cleaned_html = re.sub(r'&\\w+;', ' ', cleaned_html)\n",
    "        cleaned_html = re.sub(r\"&[a-z]+;\", \" \", cleaned_html)\n",
    "\n",
    "    else:\n",
    "        # remove all other html tags except\n",
    "        cleaned_html = re.sub(r'(<br\\s*/?>|</div>|</p>|</span>|</li>|</table>)', '\\n', raw_html, flags=re.IGNORECASE)\n",
    "        cleaned_html = re.sub(r'<(?!/)[^>]+>', '', cleaned_html, flags=re.IGNORECASE)\n",
    "\n",
    "    # replace HTML entities (&#160;）with space\n",
    "    cleaned_html = re.sub(r'&#\\d+;|nbsp', ' ', cleaned_html)\n",
    "    cleaned_html = re.sub(r'\\s+', ' ', cleaned_html)\n",
    "\n",
    "    # remove urls\n",
    "    cleaned_url = re.sub(r\"\\(http[s]?://\\S+\\)\", \"\", cleaned_html)\n",
    "    cleaned_url = re.sub(r\"http[s]?://\\S+\", \"\", cleaned_url)\n",
    "\n",
    "    # remove multiple spaces\n",
    "    cleaned_space = re.sub(r'\\s+', ' ', cleaned_url)\n",
    "\n",
    "    # fix the error that /s/ is splitted into / s / in GOOG_10-K_2021.html\n",
    "    clean_spe = re.sub(r'/\\s*S\\s*/', '/s/', cleaned_space, flags=re.IGNORECASE)\n",
    "\n",
    "    # fix the error: ALICE is splitted into multiple A LICE in MSFT_10-K_2021.html\n",
    "    clean_spe = re.sub(r'(\\b[A-Z])\\s([A-Z]{2,}\\b)', r'\\1\\2', clean_spe)\n",
    "\n",
    "    # fix the error: can not find the signature section in MSFT_10-K_2021.html\n",
    "    cleaned = re.sub(r'SIGNAT\\s*URES', 'SIGNATURES', clean_spe, flags=re.IGNORECASE)\n",
    "\n",
    "    return cleaned.strip()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Step 3: Extract all necessary information from the cleaned text\n",
    "\"\"\"\n",
    "def convert_date(date_str):\n",
    "    \"\"\" This is a helper function that converts date to ISO format \"\"\"\n",
    "\n",
    "    try:\n",
    "        date = datetime.strptime(date_str.strip(), \"%B %d, %Y\").date().isoformat()\n",
    "    except ValueError:\n",
    "        date = re.sub(r\"\\s+,\", \",\", date_str) # e.g.: 'For the fiscal year ended December 31 , 2023'\n",
    "        date = datetime.strptime(date, \"%B %d, %Y\").date().isoformat()\n",
    "    return date\n",
    "\n",
    "\n",
    "def find_signature_pattern(text):\n",
    "    \"\"\" This is a helper function that is used to find the SIGNATURES sections\"\"\"\n",
    "    signature_pattern = r\"SIGNATURES\\s*Pursuant to the requirements of Section.*?(?=EXHIBIT INDEX|$)\"\n",
    "    signature_section_match = re.search(signature_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if signature_section_match:\n",
    "        signature_section = signature_section_match.group(0)\n",
    "        return signature_section\n",
    "\n",
    "    return ''\n",
    "\n",
    "\n",
    "def extract_fiscal_year(text):\n",
    "    \"\"\" 1. The date of the fiscal year-end (ensure it is formatted in ISO-format)\n",
    "\n",
    "    Currently, relevant information is in the beginning of the document, e.g.:\n",
    "     'For the fiscal year ended January 31, 2024, or'\n",
    "     Search for the fiscal year and return it in ISO-format.\n",
    "\n",
    "     \"\"\"\n",
    "    match = re.search(r\"for the fiscal year ended (\\w+\\s\\d{1,2}\\s*,\\s\\d{4})\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        fiscal_year_str = match.group(1)\n",
    "        fiscal_year_iso = convert_date(fiscal_year_str)\n",
    "        return fiscal_year_iso\n",
    "\n",
    "    return 'N/A'\n",
    "\n",
    "\n",
    "def extract_legal_proceedings(text):\n",
    "    \"\"\" 2. The content of “Item 3. LEGAL PROCEEDINGS”.\"\"\"\n",
    "\n",
    "        # Find all matches\n",
    "    matches = list(re.finditer(r\"(?:\\bItem\\s3\\.\\s*Legal Proceedings\\.?\\b)\\b(.*?)(?=\\bItem\\s4\\b|$)\", text, re.IGNORECASE | re.DOTALL))\n",
    "\n",
    "    # Get the second match if available\n",
    "    if len(matches) > 1:\n",
    "        second_match = matches[-1].group(1).strip()  # Extract the second occurrence\n",
    "        return second_match\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0].group(1).strip()\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "        # match = list(re.finditer(r\"(?<=\\bItem 3\\.\\sLegal Proceedings\\b)(.*?)(?=\\bItem 4\\.\\b|$)\", text, re.IGNORECASE|re.DOTALL))\n",
    "        # return match[0].group(1).strip() if match else 'N/A'\n",
    "\n",
    "\n",
    "def extract_signature_date(text):\n",
    "    \"\"\" 3. The date of signature(s) (ensure it is formatted in ISO-format).\"\"\"\n",
    "    # find the signature section\n",
    "    signature_section = find_signature_pattern(text)\n",
    "    if signature_section:\n",
    "\n",
    "        signature_date_match = re.search(r\"\\s*(\\w+\\s\\d{1,2}\\s*,\\s*\\d{4})\", signature_section)\n",
    "\n",
    "        if signature_date_match:\n",
    "            signature_date = convert_date(signature_date_match.group(1))\n",
    "            return signature_date\n",
    "    return 'N/A'\n",
    "\n",
    "\n",
    "def extract_signers(text):\n",
    "    \"\"\" 4. Who signed the report?\n",
    "    If there are multiple signatures, all of them have to be listed (comma separated).\n",
    "    Do not include the audit firm – in case it is given in the report.\n",
    "    \"\"\"\n",
    "    # find the signature section\n",
    "    signature_section = find_signature_pattern(text)\n",
    "    if signature_section:\n",
    "\n",
    "        cleaned_signers = []\n",
    "        raw_signers = re.findall(r\"/s/\\s*([A-Z][a-zA-Z.\\-]+\\s[A-Z][a-zA-Z.\\-]+(?:\\s[A-Z][a-zA-Z.\\-]+)?)\", signature_section)\n",
    "\n",
    "        for signer in raw_signers:\n",
    "            signer = signer.strip()\n",
    "\n",
    "            words = signer.split()\n",
    "            # remove the html tag I initially kept\n",
    "            if words[-1] == '</td>' or words[-1] == '</tr>':\n",
    "                    signer = ' '.join(words[:-2])\n",
    "            # avoid duplicate occurrences of the same signer\n",
    "            if signer.lower() not in [s.lower() for s in cleaned_signers]:\n",
    "                cleaned_signers.append(signer)\n",
    "\n",
    "        return cleaned_signers\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "def save_text_to_file(text, file_name):\n",
    "    \"\"\" This function saves the extracted text to a file \"\"\"\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "\n",
    "def process_file(file):\n",
    "    \"\"\" This function processes the raw content of a file and extracts the necessary information \"\"\"\n",
    "    clean_content_one = clean_html(file)\n",
    "    clean_content_two = clean_html(file, remove_tags=False)\n",
    "\n",
    "    # Save cleaned text to a .txt file\n",
    "    save_text_to_file(clean_content_one, f\"{filename}_cleaned.txt\")\n",
    "\n",
    "    fiscal_year = extract_fiscal_year(clean_content_one)\n",
    "    legal_proceedings = extract_legal_proceedings(clean_content_one)\n",
    "    signature_date = extract_signature_date(clean_content_one)\n",
    "    signers = extract_signers(clean_content_two)\n",
    "\n",
    "    if not signers:\n",
    "        signers = extract_signers(clean_content_one)\n",
    "    return {\n",
    "        \"fiscal_year\": fiscal_year,\n",
    "        \"legal_proceedings\": legal_proceedings,\n",
    "        \"signature_date\": signature_date,\n",
    "        \"signers\": signers\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "Step 4: Iterate over all files in the directory and process them\n",
    "\"\"\"\n",
    "current_directory = Path.cwd()\n",
    "results = []\n",
    "for html_file in current_directory.glob('*.html'):\n",
    "    with html_file.open('r', encoding='utf-8') as f:\n",
    "        filename = html_file.name\n",
    "        raw_content = f.read()\n",
    "        result = process_file(raw_content)\n",
    "        result['file_name'] = filename\n",
    "\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('10k_results.csv', index=False)\n",
    "df.head(10)"
   ],
   "id": "a5d29f3285f6bad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T19:57:42.427925Z",
     "start_time": "2025-02-06T19:57:42.425805Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3cfb3d756960ec2a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
